{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\ntest_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Getting Data Ready**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nIMG_SIZE = (224,224)\nBATCH_SIZE = 32\n\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                 validation_split=0.2,\n                                                                 subset='training',\n                                                                 seed=42,\n                                                                 label_mode='categorical',\n                                                                 image_size=IMG_SIZE)\nvalid_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                 validation_split=0.2,\n                                                                 subset='validation',\n                                                                 seed=42,\n                                                                 label_mode='categorical',\n                                                                 image_size=IMG_SIZE,\n                                                                 shuffle=False)\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                                label_mode='categorical',\n                                                                image_size=IMG_SIZE,\n                                                                shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **VISUALIZING DATA**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Get the class names from the dataset\nclass_names = train_data.class_names\n\n# Count the occurrences of each class in the training dataset\ntrain_labels = []\nfor images, labels in train_data:\n    train_labels.extend(np.argmax(labels, axis=1))\n\nclass_counts = np.bincount(train_labels)\n\n\ncustom_space=0.5\n\n# Create a bar plot\nplt.figure(figsize=(25, 12))\nplt.bar(class_names, class_counts, width=1.0 - custom_space)\nplt.xlabel('Classes', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.title('Class Distribution in Training Dataset')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the class names from the dataset\nclass_names = test_data.class_names\n\n# Count the occurrences of each class in the training dataset\ntest_labels = []\nfor images, labels in test_data:\n    test_labels.extend(np.argmax(labels, axis=1))\n\nclass_counts = np.bincount(test_labels)\n\n\ncustom_space=0.5\n\n# Create a bar plot\nplt.figure(figsize=(25, 12))\nplt.bar(class_names, class_counts, width=1.0 - custom_space)\nplt.xlabel('Classes', fontsize=20)\nplt.ylabel('Counts', fontsize=20)\nplt.title('Class Distribution in Training Dataset')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Checkpoint**\n---\n","metadata":{}},{"cell_type":"code","source":"checkpoint_path = 'fruits_classification_model_checkpoint.h5'\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                         save_weights_only=True,\n                                                         monitor='val_accuracy',\n                                                         save_best_only=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation**\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.models import Sequential\n\ndata_augmentation = Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomHeight(0.2),\n    preprocessing.RandomWidth(0.2),\n    preprocessing.RandomZoom(0.2),\n    preprocessing.Rescaling(1/255.)\n],name='data_augmenation')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<h1><center><b> Model Building </b></center></h1> \n\n<table style=\"width:20%\">\n  <tr>\n    <th><h2><center><b> Model Names </b></center></h2></th>\n  </tr>\n  <tr>\n    <td><h4><center><b> EfficientNetB3 </b></center></h4></td>\n  </tr>\n  <tr>\n    <td><h4><center><b> MobileNetV2 </b></center></h4></td>\n  </tr>\n  <tr>\n    <td><h4><center><b> VGG16 </b></center></h4></td>\n  </tr>\n</table>","metadata":{}},{"cell_type":"markdown","source":"---\n<h3><center><b> EfficientNetB3 </b></center></h3> \n\n---","metadata":{}},{"cell_type":"code","source":"base_model_1 = tf.keras.applications.EfficientNetB3(include_top=False)\nbase_model_1.trainable = False\n\ninputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model_1(x, training=False)\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\noutputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x)\nefficient_model = tf.keras.Model(inputs, outputs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\nefficient_model_hist = efficient_model.fit(train_data,\n                 epochs=10,\n                 validation_data=valid_data,\n                 validation_steps=len(valid_data)//BATCH_SIZE,\n                 callbacks=[checkpoint_callback])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient_model_loss, efficient_model_acc = efficient_model.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<h1><center><b> MobileNetV2 </b></center></h1> \n\n---","metadata":{}},{"cell_type":"code","source":"base_model_2 = tf.keras.applications.MobileNetV2(include_top=False)\nbase_model_2.trainable = False\n\ninputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model_2(x, training=False)\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\noutputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x)\nmobilenet_model = tf.keras.Model(inputs, outputs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\n\nmobilenet_model_hist = mobilenet_model.fit(train_data,\n                 epochs=10,\n                 validation_data=valid_data,\n                 validation_steps= len(valid_data)//BATCH_SIZE,\n                 callbacks=[checkpoint_callback])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model_loss, mobilenet_model_acc = mobilenet_model.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n<h1><center><b> VGG16 </b></center></h1> \n\n---","metadata":{}},{"cell_type":"code","source":"base_model_3 = tf.keras.applications.VGG16(include_top=False)\nbase_model_3.trainable = False\n\ninputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model_3(x, training=False)\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\noutputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x)\nvgg16_model = tf.keras.Model(inputs, outputs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\n\nvgg16_model_hist = vgg16_model.fit(train_data,\n                 epochs=10,\n                 validation_data=valid_data,\n                 validation_steps=len(valid_data)//BATCH_SIZE,\n                 callbacks=[checkpoint_callback])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model_loss, vgg16_model_acc = vgg16_model.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------------------------------------------------------------------\\n\")\n\nprint(\"\\t\\t Training Loss  |  Training Accuracy \")\n\nprint(\"\\nEfficientNetB3 :  {:.4} \\t|\\t {:.4}%\".format(efficient_model_loss, efficient_model_acc*100))\nprint(\"\\nMobileNetV2    :  {:.4} \\t|\\t {:.4}%\".format(mobilenet_model_loss, mobilenet_model_acc*100))\nprint(\"\\nVGG16          :  {:.4} \\t|\\t {:.4}%\".format(vgg16_model_loss, vgg16_model_acc*100))\n\nprint(\"\\n---------------------------------------------------------------------\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Hyperparameter Tuning**\n\nWe will be fine tunning both the models, we will be unfreezing the last 5 layers of base models.","metadata":{}},{"cell_type":"markdown","source":"**EfficientNetB3 Fine Tune**","metadata":{}},{"cell_type":"code","source":"# Unfreeze all of the layers in the base model\nbase_model_1.trainable = True\n\n# Refreeze every layer except for the last 5\nfor layer in base_model_1.layers[:-5]:\n  layer.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recompile model with lower learning rate\nefficient_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n              metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What layers in the model are trainable?\nfor layer in efficient_model.layers:\n  print(layer.name, layer.trainable)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check which layers are trainable\nfor layer_number, layer in enumerate(base_model_1.layers):\n  print(layer_number, layer.name, layer.trainable)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune for 10 more epochs\nfine_tune_epochs = 20 # model has already done 10 epochs, this is the total number of epochs we're after (10+10=20)\n\nhistory_1 = efficient_model.fit(train_data,\n                    epochs=fine_tune_epochs,\n                    validation_data=valid_data,\n                    validation_steps=len(valid_data)//BATCH_SIZE,\n                    initial_epoch=efficient_model_hist.epoch[-1]) # start from previous last epoch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient_model_fine_loss, efficient_model_fine_acc = efficient_model.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MobileNetV2 Fine Tune**","metadata":{}},{"cell_type":"code","source":"# Unfreeze all of the layers in the base model\nbase_model_2.trainable = True\n\n# Refreeze every layer except for the last 5\nfor layer in base_model_2.layers[:-5]:\n  layer.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recompile model with lower learning rate\nmobilenet_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n              metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What layers in the model are trainable?\nfor layer in mobilenet_model.layers:\n  print(layer.name, layer.trainable)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check which layers are trainable\nfor layer_number, layer in enumerate(base_model_2.layers):\n  print(layer_number, layer.name, layer.trainable)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune for 10 more epochs\nfine_tune_epochs = 20 # model has already done 10 epochs, this is the total number of epochs we're after (10+10=20)\n\nhistory_2 = mobilenet_model.fit(train_data,\n                    epochs=fine_tune_epochs,\n                    validation_data=valid_data,\n                    validation_steps=len(valid_data)//BATCH_SIZE,\n                    initial_epoch=mobilenet_model_hist.epoch[-1]) # start from previous last epoch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model_fine_loss, mobilenet_model_fine_acc = mobilenet_model.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}